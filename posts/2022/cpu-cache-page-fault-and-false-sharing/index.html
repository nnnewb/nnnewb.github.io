<!doctype html><html lang=zh><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta content="text/html; charset=UTF-8" http-equiv=content-type><meta content="width=device-width,initial-scale=1,user-scalable=no" name=viewport><meta content="index, follow" name=robots><title>CPU缓存、缺页和伪共享</title><meta content=CPU缓存、缺页和伪共享 name=title><meta content=一点点从这个世界上消失。 name=description><meta content=website property=og:type><meta content=https://nnnewb.github.io/posts/2022/cpu-cache-page-fault-and-false-sharing/ property=og:url><meta content="weakptr's blog" property=og:site_name><meta content=CPU缓存、缺页和伪共享 property=og:title><meta content=一点点从这个世界上消失。 property=og:description><meta content=https://nnnewb.github.io/image/favicon.ico property=og:image><meta content=summary_large_image property=twitter:card><meta content=https://nnnewb.github.io/posts/2022/cpu-cache-page-fault-and-false-sharing/ property=twitter:url><meta content=CPU缓存、缺页和伪共享 property=twitter:title><meta content=一点点从这个世界上消失。 property=twitter:description><meta content=https://nnnewb.github.io/image/favicon.ico property=twitter:image><link href=https://nnnewb.github.io/posts/2022/cpu-cache-page-fault-and-false-sharing/ rel=canonical><link rel="shortcut icon" href=https://nnnewb.github.io/image/favicon.ico type=image/x-icon><link href=https://nnnewb.github.io/css/reset.css rel=stylesheet><link href=https://nnnewb.github.io/css/pallete.css rel=stylesheet><link href=https://nnnewb.github.io/css/suCSS.css rel=stylesheet><link href=https://nnnewb.github.io/archive.css rel=stylesheet><link href=https://nnnewb.github.io/style.css rel=stylesheet><script defer src=https://nnnewb.github.io/js/script.js></script><link crossorigin href=https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css integrity=sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y rel=stylesheet><script crossorigin defer integrity=sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx src=https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js></script><script crossorigin defer integrity=sha384-zWYbd0NBwgTsgIdFKVprSfTh1mbMPe5Hz1X3yY4Sd1h/K1cQoUe36OGwAGz/PcDy src=https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/mathtex-script-type.min.js></script><script crossorigin defer integrity=sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe src=https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js></script><script>document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            // customised options
            // • auto-render specific keys, e.g.:
            delimiters: [
                { left: '$$', right: '$$', display: true },
                { left: '$', right: '$', display: false },
                { left: '\\(', right: '\\)', display: false },
                { left: '\\[', right: '\\]', display: false }
            ],
            // • rendering keys, e.g.:
            throwOnError: true
        });
    });</script><script src=https://cdn.jsdelivr.net/npm/mermaid@11.6.0/dist/mermaid.min.js></script><script>document.addEventListener('DOMContentLoaded', function () {
        // 查找所有具有 'pre' 标签且类名为 'language-mermaid' 的元素
        const mermaidElements = document.getElementsByClassName('language-mermaid');
        for (let i = 0; i < mermaidElements.length; i++) {
            const el = mermaidElements.item(i);
            if (el.tagName === "PRE" && !el.classList.contains('mermaid')) {
                el.innerHTML = el.textContent;
                el.classList.add('mermaid');
            }
        }

        mermaid.initialize({ startOnLoad: true, theme: 'dark', });
    })</script><script>if (window.location.hostname.toLowerCase() !== 'localhost' && window.location.hostname !== '127.0.0.1') {
        var _hmt = _hmt || [];
        (function () {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?dbb9df33a2de52aede8bccd84a7493ad";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    }</script><link href=https://chinese-fonts-cdn.deno.dev/packages/lxgwwenkaibright/dist/LXGWBright-Medium/result.css rel=stylesheet><link href=https://chinese-fonts-cdn.deno.dev/packages/maple-mono-cn/dist/MapleMono-CN-Regular/result.css rel=stylesheet><body><header><nav id=nav-bar><a href=/> 首页 </a>  /  <a href=/posts/> 文章 </a>  /  <a href=/categories/> 分类 </a>  /  <a href=/tags/> 标签 </a>  /  <a href=/search/> 搜索 </a>  /  <div><input id=theme-toggle style=display:none type=checkbox><label for=theme-toggle id=theme-toggle-label><svg class=icons id=theme-icon><use href=https://nnnewb.github.io/icons.svg#lightMode></use></svg></label><audio id=theme-sound><source src=https://nnnewb.github.io/click.ogg type=audio/ogg></audio></div></nav></header><main><h1>CPU缓存、缺页和伪共享</h1><p class=author-line>作于：2022-02-15 17:11 ，预计阅读时间 16 分钟<article><h2 id=qian-yan>前言</h2><p>看B树的时候发现对缓存还是不够了解，但 cache line 又很神奇。要是有些比较吃CPU的代码改一下结构和访问方式啥的就能白嫖个50%性能提升那岂不是美哉。结合下面的参考文章大概聊一下。<ul><li><a href=http://igoro.com/archive/gallery-of-processor-cache-effects/>Gallery of Processor Cache Effects</a></ul><h2 id=huan-cun-xing>缓存行</h2><h3 id=jie-shao>介绍</h3><p>首先，缓存行<strong>不是</strong>“行”，这是对 <em>cache line</em> 的直译，<em>cache line</em> 和 <em>cache block</em> 是同义的，忽略这个“行”字即可。<p>cache line 指的是 CPU 高速缓存（L1~L3）中的一个缓存块，通常大小在 32/64/128 bytes ，现在常见的应该是 64 bytes 。cache line 之所以重要，是因为这是 CPU 访问主存的必经之路，频繁访问主存数据的场合，或者并发编程时，cache line 的影响还是不容忽视的。<h3 id=jian-dan-de-ji-zhun-ce-shi>简单的基准测试</h3><p>光是说 cache line 多重要没有卵用，写个 demo 看看 cache line 的影响更直观。来一个最简单不过的单链表遍历。<pre class=language-c++ data-lang=c++ style=color:#fdf4c1aa;background-color:#282828><code class=language-c++ data-lang=c++><span style=color:#fa5c4b>#include </span><span style=color:#b8bb26>&lt;chrono>
</span><span style=color:#fa5c4b>#include </span><span style=color:#b8bb26>&lt;cstddef>
</span><span style=color:#fa5c4b>#include </span><span style=color:#b8bb26>&lt;functional>
</span><span style=color:#fa5c4b>#include </span><span style=color:#b8bb26>&lt;iostream>
</span><span style=color:#fa5c4b>#include </span><span style=color:#b8bb26>&lt;iterator>
</span><span style=color:#fa5c4b>#include </span><span style=color:#b8bb26>&lt;ostream>
</span><span style=color:#fa5c4b>#include </span><span style=color:#b8bb26>&lt;string>
</span><span>
</span><span style=color:#fa5c4b>using namespace</span><span> std;
</span><span style=color:#fa5c4b>using namespace</span><span> std::chrono;
</span><span>
</span><span style=color:#fa5c4b>typedef struct</span><span> _data {
</span><span>  </span><span style=color:#fa5c4b>struct</span><span> _data </span><span style=color:#fe8019>*</span><span>next;
</span><span>  </span><span style=color:#fa5c4b>int</span><span> value;
</span><span>} </span><span style=color:#8ec07c>mydata</span><span>;
</span><span>
</span><span style=color:#fa5c4b>void </span><span style=color:#8ec07c>time_it</span><span>(</span><span style=color:#fa5c4b>const</span><span> std::string </span><span style=color:#fdf4c1>name</span><span>, function&lt;</span><span style=color:#fa5c4b>void</span><span>(</span><span style=color:#fa5c4b>void</span><span>)> </span><span style=color:#fdf4c1>fn</span><span>) {
</span><span>  </span><span style=color:#fa5c4b>auto</span><span> start </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>system_clock::now()</span><span>;
</span><span>  </span><span style=color:#fdf4c1>fn()</span><span>;
</span><span>  </span><span style=color:#fa5c4b>auto</span><span> stop </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>system_clock::now()</span><span>;
</span><span>  cout </span><span style=color:#fe8019>&lt;&lt;</span><span> name </span><span style=color:#fe8019>&lt;&lt; </span><span style=color:#b8bb26>": " </span><span style=color:#fe8019>&lt;&lt; </span><span style=color:#fdf4c1>duration_cast&lt;milliseconds>(stop </span><span style=color:#fe8019>-</span><span style=color:#fdf4c1> start)</span><span>.</span><span style=color:#fdf4c1>count</span><span>()
</span><span>       </span><span style=color:#fe8019>&lt;&lt; </span><span style=color:#b8bb26>"ms" </span><span style=color:#fe8019>&lt;&lt;</span><span> endl;
</span><span>}
</span><span>
</span><span style=color:#fa5c4b>int </span><span style=color:#8ec07c>main</span><span>(</span><span style=color:#fa5c4b>void</span><span>) {
</span><span>  </span><span style=color:#928374;font-style:italic>// 一次分配，内存连续
</span><span>  </span><span style=color:#fa5c4b>auto</span><span> list1 </span><span style=color:#fe8019>= </span><span style=color:#fa5c4b>new</span><span> mydata[</span><span style=color:#d3869b>1024 </span><span style=color:#fe8019>* </span><span style=color:#d3869b>1024 </span><span style=color:#fe8019>* </span><span style=color:#d3869b>64</span><span>];
</span><span>  </span><span style=color:#fa5c4b>auto</span><span> cur </span><span style=color:#fe8019>=</span><span> list1;
</span><span>  </span><span style=color:#fa5c4b>for </span><span>(</span><span style=color:#fa5c4b>int</span><span> i </span><span style=color:#fe8019>= </span><span style=color:#d3869b>0</span><span>; i </span><span style=color:#fe8019>&lt; </span><span style=color:#d3869b>1024 </span><span style=color:#fe8019>* </span><span style=color:#d3869b>1024 </span><span style=color:#fe8019>* </span><span style=color:#d3869b>64 </span><span style=color:#fe8019>- </span><span style=color:#d3869b>1</span><span>; i</span><span style=color:#fe8019>++</span><span>) {
</span><span>    cur-></span><span style=color:#fdf4c1>next </span><span style=color:#fe8019>= &</span><span>list1[i </span><span style=color:#fe8019>+ </span><span style=color:#d3869b>1</span><span>];
</span><span>    cur </span><span style=color:#fe8019>=</span><span> cur-></span><span style=color:#fdf4c1>next</span><span>;
</span><span>  }
</span><span>  list1[</span><span style=color:#d3869b>1024 </span><span style=color:#fe8019>* </span><span style=color:#d3869b>1024 </span><span style=color:#fe8019>- </span><span style=color:#d3869b>1</span><span>].</span><span style=color:#fdf4c1>next </span><span style=color:#fe8019>= </span><span style=color:#d3869b>NULL</span><span>;
</span><span>
</span><span>  </span><span style=color:#928374;font-style:italic>// 分别分配，内存不连续
</span><span>  </span><span style=color:#fa5c4b>auto</span><span> list2 </span><span style=color:#fe8019>= </span><span style=color:#fa5c4b>new </span><span style=color:#fdf4c1>mydata()</span><span>;
</span><span>  </span><span style=color:#fa5c4b>auto</span><span> cur2 </span><span style=color:#fe8019>=</span><span> list2;
</span><span>  </span><span style=color:#fa5c4b>for </span><span>(</span><span style=color:#fa5c4b>int</span><span> i </span><span style=color:#fe8019>= </span><span style=color:#d3869b>0</span><span>; i </span><span style=color:#fe8019>&lt; </span><span style=color:#d3869b>1024 </span><span style=color:#fe8019>* </span><span style=color:#d3869b>1024 </span><span style=color:#fe8019>* </span><span style=color:#d3869b>64 </span><span style=color:#fe8019>- </span><span style=color:#d3869b>1</span><span>; i</span><span style=color:#fe8019>++</span><span>) {
</span><span>    cur2-></span><span style=color:#fdf4c1>next </span><span style=color:#fe8019>= </span><span style=color:#fa5c4b>new </span><span style=color:#fdf4c1>mydata()</span><span>;
</span><span>    cur2 </span><span style=color:#fe8019>=</span><span> cur2-></span><span style=color:#fdf4c1>next</span><span>;
</span><span>  }
</span><span>
</span><span>  </span><span style=color:#928374;font-style:italic>// 遍历连续的链表
</span><span>  </span><span style=color:#fdf4c1>time_it(</span><span style=color:#b8bb26>"first"</span><span style=color:#fdf4c1>, [</span><span style=color:#fe8019>&</span><span style=color:#fdf4c1>]() {
</span><span style=color:#fdf4c1>    </span><span style=color:#fa5c4b>for </span><span style=color:#fdf4c1>(</span><span style=color:#fa5c4b>auto</span><span style=color:#fdf4c1> ptr </span><span style=color:#fe8019>=</span><span style=color:#fdf4c1> list1; ptr </span><span style=color:#fe8019>!= </span><span style=color:#d3869b>NULL</span><span style=color:#fdf4c1>; ptr </span><span style=color:#fe8019>=</span><span style=color:#fdf4c1> ptr->next) {
</span><span style=color:#fdf4c1>      ptr->value </span><span style=color:#fe8019>*= </span><span style=color:#d3869b>3</span><span style=color:#fdf4c1>;
</span><span style=color:#fdf4c1>    }
</span><span style=color:#fdf4c1>  })</span><span>;
</span><span>
</span><span>  </span><span style=color:#928374;font-style:italic>// 遍历不连续的链表
</span><span>  </span><span style=color:#fdf4c1>time_it(</span><span style=color:#b8bb26>"second"</span><span style=color:#fdf4c1>, [</span><span style=color:#fe8019>&</span><span style=color:#fdf4c1>]() {
</span><span style=color:#fdf4c1>    </span><span style=color:#fa5c4b>for </span><span style=color:#fdf4c1>(</span><span style=color:#fa5c4b>auto</span><span style=color:#fdf4c1> ptr </span><span style=color:#fe8019>=</span><span style=color:#fdf4c1> list2; ptr </span><span style=color:#fe8019>!= </span><span style=color:#d3869b>NULL</span><span style=color:#fdf4c1>; ptr </span><span style=color:#fe8019>=</span><span style=color:#fdf4c1> ptr->next) {
</span><span style=color:#fdf4c1>      ptr->value </span><span style=color:#fe8019>*= </span><span style=color:#d3869b>3</span><span style=color:#fdf4c1>;
</span><span style=color:#fdf4c1>    }
</span><span style=color:#fdf4c1>  })</span><span>;
</span><span>  </span><span style=color:#fa5c4b>return </span><span style=color:#d3869b>0</span><span>;
</span><span>}
</span></code></pre><p>为了体现出差异，一共遍历了 <code>1024*1024*64</code>个元素，每个元素 8 个字节，一共是512M数据。<p>结果如下。<pre style=color:#fdf4c1aa;background-color:#282828><code><span>weakptr  数据结构  ♥ 09:42  clang++.exe -m32 -O2 main.cpp -o main.exe
</span><span>weakptr  数据结构  ♥ 09:43  ./main.exe
</span><span>first: 2ms
</span><span>second: 239ms
</span></code></pre><p>启用了<code>O2</code>级别优化的情况下，遍历连续分配和不连续分配的链表时，速度相差达到了惊人的一百多倍。<p>是<code>O2</code>优化掉了第一种连续分配的链表遍历吗？<code>-O0</code> 禁止优化看看。<pre style=color:#fdf4c1aa;background-color:#282828><code><span>weakptr  数据结构  ♥ 09:44  clang++.exe -m32 -O0 main.cpp -o main.exe
</span><span>weakptr  数据结构  ♥ 09:45  ./main.exe
</span><span>first: 3ms
</span><span>second: 262ms
</span></code></pre><p>并没有任何改善。<p>因为考虑是和内存相关，影响内存访问性能的因素可以很自然想到缓存和缺页这两条。<p>缓存指的是 cache line，一般说 false sharing 的时候提加 padding 对齐比较多。另一个情况就是遍历的时候，如果数据比较密集，那从主存刷新 cache line 就会更少，缓存利用更充分。所以像是数组这样的连续内存遍历速度通常远比链表之类的结构快。<p>缺页又是另一个问题，缺页异常发生的几个常见场景包括：第一次访问分配好的内存，访问被交换到硬盘上的内存，<code>mmap</code> ，以及<code>SIGSEGV</code>等情况。一般来说的话，连续的内存分配下一次缺页可以得到连续的N个元素，不连续的分配第一次访问N个元素，最坏的情况下可能就要N次缺页异常。<h3 id=que-ye-yi-chang>缺页异常</h3><p>先看缺页。这里使用微软的 Process Explorer 来观察 Page Fault 的出现情况。为了有效观察到page fault发生，我修改了一下代码，在 <code>time_it</code> 函数里添加上了简单的 page fault 观测。<p><em>提示，也可以用 Process Explorer 等工具观测程序运行时的 Page Fault 数量，但直接在代码里嵌入观测还是最准确的。如果有更好用的性能分析工具的话当然更好。</em><pre class=language-c++ data-lang=c++ style=color:#fdf4c1aa;background-color:#282828><code class=language-c++ data-lang=c++><span style=color:#fabd2f>DWORD </span><span style=color:#8ec07c>getPageFaultCount</span><span>() {
</span><span>    </span><span style=color:#fa5c4b>auto</span><span> proc </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>GetCurrentProcess()</span><span>;
</span><span>    PROCESS_MEMORY_COUNTERS counters;
</span><span>    </span><span style=color:#fa5c4b>if </span><span>(</span><span style=color:#fdf4c1>GetProcessMemoryInfo(proc, </span><span style=color:#fe8019>&</span><span style=color:#fdf4c1>counters, </span><span style=color:#fe8019>sizeof</span><span style=color:#fdf4c1>(counters)) </span><span style=color:#fe8019>== </span><span style=color:#d3869b>FALSE</span><span>) {
</span><span>        cerr </span><span style=color:#fe8019>&lt;&lt; </span><span style=color:#b8bb26>"GetProcessMemoryInfo failed, error " </span><span style=color:#fe8019>&lt;&lt; </span><span style=color:#fdf4c1>GetLastError() </span><span style=color:#fe8019>&lt;&lt;</span><span> endl;
</span><span>    }
</span><span>    </span><span style=color:#fa5c4b>return</span><span> counters.</span><span style=color:#fdf4c1>PageFaultCount</span><span>;
</span><span>}
</span><span>
</span><span style=color:#fa5c4b>void </span><span style=color:#8ec07c>time_it</span><span>(</span><span style=color:#fa5c4b>const</span><span> string </span><span style=color:#fdf4c1>name</span><span>, function&lt;</span><span style=color:#fa5c4b>void</span><span>(</span><span style=color:#fa5c4b>void</span><span>)> </span><span style=color:#fdf4c1>fn</span><span>) {
</span><span>    </span><span style=color:#fa5c4b>auto</span><span> before </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>getPageFaultCount()</span><span>;
</span><span>    </span><span style=color:#fa5c4b>auto</span><span> start </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>system_clock::now()</span><span>;
</span><span>    </span><span style=color:#fdf4c1>fn()</span><span>;
</span><span>    </span><span style=color:#fa5c4b>auto</span><span> stop </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>system_clock::now()</span><span>;
</span><span>    </span><span style=color:#fa5c4b>auto</span><span> after </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>getPageFaultCount()</span><span>;
</span><span>    cout </span><span style=color:#fe8019>&lt;&lt;</span><span> name </span><span style=color:#fe8019>&lt;&lt; </span><span style=color:#b8bb26>": " </span><span style=color:#fe8019>&lt;&lt; </span><span style=color:#fdf4c1>duration_cast&lt;milliseconds>(stop </span><span style=color:#fe8019>-</span><span style=color:#fdf4c1> start)</span><span>.</span><span style=color:#fdf4c1>count</span><span>()
</span><span>         </span><span style=color:#fe8019>&lt;&lt; </span><span style=color:#b8bb26>"ms, page fault count: " </span><span style=color:#fe8019>&lt;&lt;</span><span> after </span><span style=color:#fe8019>-</span><span> before </span><span style=color:#fe8019>&lt;&lt;</span><span> endl;
</span><span>}
</span></code></pre><p>然后对两个用例进行测试。<pre style=color:#fdf4c1aa;background-color:#282828><code><span>initialization-1: 337ms, page fault count: 131329
</span><span>initialization-2: 3591ms, page fault count: 265660
</span><span>iteration-1: 3ms, page fault count: 0
</span><span>iteration-2: 294ms, page fault count: 0
</span></code></pre><p>可以清晰地看到，在链表的初始化阶段，非连续分配的链表产生了连续分配的链表差不多两倍的 page fault，耗时接近十倍——我还得澄清一下这不是在暗示十倍的耗时都是 page fault 造成的，但 page fault 在其中也消耗了一部分资源总归是毫无疑问的。<p>但随后的迭代阶段里并没有新的 page fault 产生，因为 两次 512M 的分配再加上循环new，堆维护指针的开销，差不多1.5G，还没有耗尽可用内存。<p>排除 page fault 的影响后，现在考虑另一个影响因素：缓存。<h3 id=huan-cun-xing-1>缓存行</h3><p>关于缓存的分析这里使用了 Intel VTune Profiler 作为分析工具，来提取缓存命中情况。为了让VTune抓取更多信息来分析，对benchmark代码再次修改，遍历一次改成遍历100次。<pre class=language-c++ data-lang=c++ style=color:#fdf4c1aa;background-color:#282828><code class=language-c++ data-lang=c++><span style=color:#fa5c4b>for </span><span>(</span><span style=color:#fa5c4b>int</span><span> i </span><span style=color:#fe8019>= </span><span style=color:#d3869b>0</span><span>; i </span><span style=color:#fe8019>&lt; </span><span style=color:#d3869b>100</span><span>; i</span><span style=color:#fe8019>++</span><span>) {
</span><span>    </span><span style=color:#fdf4c1>time_it(</span><span style=color:#b8bb26>"iteration-2"</span><span style=color:#fdf4c1>, [</span><span style=color:#fe8019>&</span><span style=color:#fdf4c1>list2]() {
</span><span style=color:#fdf4c1>        </span><span style=color:#fa5c4b>for </span><span style=color:#fdf4c1>(</span><span style=color:#fa5c4b>auto</span><span style=color:#fdf4c1> ptr </span><span style=color:#fe8019>=</span><span style=color:#fdf4c1> list2; ptr </span><span style=color:#fe8019>!= </span><span style=color:#d3869b>NULL</span><span style=color:#fdf4c1>; ptr </span><span style=color:#fe8019>=</span><span style=color:#fdf4c1> ptr->next) {
</span><span style=color:#fdf4c1>            ptr->value </span><span style=color:#fe8019>*= </span><span style=color:#d3869b>3</span><span style=color:#fdf4c1>;
</span><span style=color:#fdf4c1>        }
</span><span style=color:#fdf4c1>    })</span><span>;
</span><span>}
</span></code></pre><p>并将连续内存分配和不连续分配分成<code>benchmark1.cpp</code>和<code>benchmark2.cpp</code>，分别用<code>-m32 -O0 -g</code> 参数编译，放进 VTune 分析内存访问性能。<p><img alt=benchmark1 src=https://nnnewb.github.io/posts/2022/cpu-cache-page-fault-and-false-sharing/image-20220215141503328.webp><p><img alt=benchmark2 src=https://nnnewb.github.io/posts/2022/cpu-cache-page-fault-and-false-sharing/image-20220215141525825.webp><p>观察图中的 LLC Miss Count 可以发现，Benchmark2 的缓存未命中次数远大于 benchmark1 ，平均时延 Average Latency 高出 13 个cycles 。这如何影响性能呢？继续观察下图 Bottom-up 中的分析。<p><img alt=benchmark1 src=https://nnnewb.github.io/posts/2022/cpu-cache-page-fault-and-false-sharing/image-20220215141832599.webp><p><img alt=benchmark2 src=https://nnnewb.github.io/posts/2022/cpu-cache-page-fault-and-false-sharing/image-20220215141933956.webp><p>能发现，在benchmark1（连续分配链表遍历测试）中，初始化耗时和遍历耗时相仿，都在300ms左右。初始化耗时可能主要来自缺页，每次遍历整个链表仅3ms左右，LLC Miss Count 为 0。这说明缓存完美地发挥了作用。<p>在 benchmark2 （循环分配节点，不连续）中，初始化耗时1.4秒，100次遍历耗时26.461秒，而且注意，LLC Miss Count 高达 47,603,332 。将这个数字除以循环次数，大约等于每个节点访问都会产生 0.7 个 LLC Miss 。<p>为什么会发生这种事？<p>benchmark1 一次 new 出连续的 <code>1024 * 1024 * 64</code> 个元素，每个元素 8 个字节，连续排列，而且构造链表时是按顺序头尾相连的。所以遍历 benchmark1 的链表时，填充好的 cache line (设为 64字节)一共有8个链表元素且连续，预取机制同时拿了下一个 cache line ，因此 CPU 几乎不用傻等主存给数据，只需要不断一个 cache line 接一个 cache line 读写即可，效率极高。<p>而 benchmark2 相反，因为链表中的每个元素都是独立分配的，依据 allocator 算法不同表现会有区别，但比较明确的是元素不大可能是在内存中连续分配。在遍历链表时，取下一个链表元素 <code>cur=cur->next </code> 后，<code>cur</code> 指向的地址大概率并不在已缓存的 cache line 中，因此每次循环里 CPU 都不得不从主存取数。可是主存取数是L1/L2 缓存取数耗时的成百上千倍，效率极低。<h3 id=wei-gong-xiang>伪共享</h3><p>继续之前再说说伪共享。<pre class=language-c++ data-lang=c++ style=color:#fdf4c1aa;background-color:#282828><code class=language-c++ data-lang=c++><span style=color:#fa5c4b>#include </span><span style=color:#b8bb26>&lt;cstddef>
</span><span style=color:#fa5c4b>#include </span><span style=color:#b8bb26>&lt;iostream>
</span><span style=color:#fa5c4b>#include </span><span style=color:#b8bb26>&lt;thread>
</span><span style=color:#fa5c4b>#include </span><span style=color:#b8bb26>&lt;functional>
</span><span style=color:#fa5c4b>#include </span><span style=color:#b8bb26>&lt;chrono>
</span><span>
</span><span style=color:#fa5c4b>using namespace</span><span> std;
</span><span style=color:#fa5c4b>using namespace</span><span> std::chrono;
</span><span>
</span><span style=color:#fa5c4b>void </span><span style=color:#8ec07c>time_it</span><span>(</span><span style=color:#fa5c4b>const</span><span> string </span><span style=color:#fdf4c1>name</span><span>, function&lt;</span><span style=color:#fa5c4b>void</span><span>(</span><span style=color:#fa5c4b>void</span><span>)> </span><span style=color:#fdf4c1>fn</span><span>) {
</span><span>    </span><span style=color:#fa5c4b>auto</span><span> start </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>system_clock::now()</span><span>;
</span><span>    </span><span style=color:#fdf4c1>fn()</span><span>;
</span><span>    </span><span style=color:#fa5c4b>auto</span><span> stop </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>system_clock::now()</span><span>;
</span><span>    cout </span><span style=color:#fe8019>&lt;&lt;</span><span> name </span><span style=color:#fe8019>&lt;&lt; </span><span style=color:#b8bb26>": " </span><span style=color:#fe8019>&lt;&lt; </span><span style=color:#fdf4c1>duration_cast&lt;milliseconds>(stop </span><span style=color:#fe8019>-</span><span style=color:#fdf4c1> start)</span><span>.</span><span style=color:#fdf4c1>count</span><span>()
</span><span>         </span><span style=color:#fe8019>&lt;&lt; </span><span style=color:#b8bb26>"ms" </span><span style=color:#fe8019>&lt;&lt;</span><span> endl;
</span><span>}
</span><span>
</span><span style=color:#fa5c4b>void </span><span style=color:#8ec07c>f</span><span>(</span><span style=color:#fa5c4b>int </span><span style=color:#fe8019>*</span><span style=color:#fdf4c1>data</span><span>) {
</span><span>    </span><span style=color:#fa5c4b>for </span><span>(</span><span style=color:#fa5c4b>int</span><span> i </span><span style=color:#fe8019>= </span><span style=color:#d3869b>0</span><span>; i </span><span style=color:#fe8019>&lt; </span><span style=color:#d3869b>10000000</span><span>; i</span><span style=color:#fe8019>++</span><span>) {
</span><span>        </span><span style=color:#fe8019>*</span><span>data </span><span style=color:#fe8019>+= </span><span style=color:#d3869b>100</span><span>;
</span><span>    }
</span><span>}
</span><span>
</span><span style=color:#fa5c4b>int </span><span style=color:#8ec07c>main</span><span>(</span><span style=color:#fa5c4b>void</span><span>) {
</span><span>    </span><span style=color:#fa5c4b>for </span><span>(</span><span style=color:#fa5c4b>int</span><span> i </span><span style=color:#fe8019>= </span><span style=color:#d3869b>0</span><span>; i </span><span style=color:#fe8019>&lt; </span><span style=color:#d3869b>100</span><span>; i</span><span style=color:#fe8019>++</span><span>) {
</span><span>        </span><span style=color:#fdf4c1>time_it(</span><span style=color:#b8bb26>"iteration"</span><span style=color:#fdf4c1>, []() {
</span><span style=color:#fdf4c1>            </span><span style=color:#fa5c4b>int</span><span style=color:#fdf4c1> a </span><span style=color:#fe8019>= </span><span style=color:#d3869b>0</span><span style=color:#fdf4c1>, b </span><span style=color:#fe8019>= </span><span style=color:#d3869b>0</span><span style=color:#fdf4c1>, c </span><span style=color:#fe8019>= </span><span style=color:#d3869b>0</span><span style=color:#fdf4c1>, d </span><span style=color:#fe8019>= </span><span style=color:#d3869b>0</span><span style=color:#fdf4c1>;
</span><span style=color:#fdf4c1>            thread </span><span style=color:#fe8019>*</span><span style=color:#fdf4c1>threads[</span><span style=color:#d3869b>4</span><span style=color:#fdf4c1>] </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>{
</span><span style=color:#fdf4c1>                </span><span style=color:#fa5c4b>new </span><span style=color:#fdf4c1>thread(f, </span><span style=color:#fe8019>&</span><span style=color:#fdf4c1>a),
</span><span style=color:#fdf4c1>                </span><span style=color:#fa5c4b>new </span><span style=color:#fdf4c1>thread(f, </span><span style=color:#fe8019>&</span><span style=color:#fdf4c1>b),
</span><span style=color:#fdf4c1>                </span><span style=color:#fa5c4b>new </span><span style=color:#fdf4c1>thread(f, </span><span style=color:#fe8019>&</span><span style=color:#fdf4c1>c),
</span><span style=color:#fdf4c1>                </span><span style=color:#fa5c4b>new </span><span style=color:#fdf4c1>thread(f, </span><span style=color:#fe8019>&</span><span style=color:#fdf4c1>d),
</span><span style=color:#fdf4c1>            };
</span><span style=color:#fdf4c1>
</span><span style=color:#fdf4c1>            </span><span style=color:#fa5c4b>for </span><span style=color:#fdf4c1>(</span><span style=color:#fa5c4b>auto</span><span style=color:#fdf4c1> t </span><span style=color:#fe8019>:</span><span style=color:#fdf4c1> threads) {
</span><span style=color:#fdf4c1>                t->join();
</span><span style=color:#fdf4c1>            }
</span><span style=color:#fdf4c1>        })</span><span>;
</span><span>    }
</span><span>    </span><span style=color:#fa5c4b>return </span><span style=color:#d3869b>0</span><span>;
</span><span>}
</span><span>
</span></code></pre><p>依然是一个很简单的 benchmark，输出如下。<pre style=color:#fdf4c1aa;background-color:#282828><code><span>iteration: 172ms
</span><span>iteration: 176ms
</span><span>iteration: 181ms
</span><span>iteration: 177ms
</span><span>iteration: 182ms
</span><span>iteration: 179ms
</span><span>... 略
</span></code></pre><p>一个非常简单的操作，4线程无锁，无 <code>volatile</code> 递增不同的四个变量，几乎看不出有什么约束导致性能低下的问题。我们通过 Intel VTune 来看看。<p><img alt="false sharing - intel VTune" src=https://nnnewb.github.io/posts/2022/cpu-cache-page-fault-and-false-sharing/image-20220215163719690.webp><p><img alt=stall src=https://nnnewb.github.io/posts/2022/cpu-cache-page-fault-and-false-sharing/image-20220215163847953.webp><p>可以看到，VTune 提示CPU花费了大量时间在傻等 cache line 写入主存。<p><img alt="hot spot" src=https://nnnewb.github.io/posts/2022/cpu-cache-page-fault-and-false-sharing/image-20220215164012789.webp><p>函数 f 出现了海量的 loads/store 操作。<p>在前文中我们聊了 cache line 的作用，这里也能看到 LLC Miss 为 0，那么为什么运行性能会这么差呢？<p>这个问题还得回到 cache line 上。在多核系统中，cache line 还要求 <strong>一致性</strong> ，一旦写 cache line 中的任意字节，都会让 <strong>整个</strong> cache line 标记为失效。在基准测试代码里，四个 int 变量被连续分配在栈上，也就是说 cache line 极有可能将这四个变量中的多个保存在同一 cache line 内。任意一个线程修改了其中一个变量，都会导致 cache line 被标为失效，其他线程或核心想要访问这四个变量之一都不得不从主存重新取数。<p>这么做的原因是为了保证数据一致性。CPU0 修改了 cache line 中的数据，还没有写回主存，其他 CPU 都不清楚 CPU0 做了什么修改，只能等待 CPU0 写回主存（或者L3），再重新从主存（或L3）取数。但我们都知道a、b、c、d并不是共享的，每个线程都只访问自己的那个变量。这种问题被称作<strong>伪共享</strong>。<p>在 VTune 中的表现，就是上图中海量的 Loads/Stores 操作。<p>如何解决呢？<p>很简单，让每个线程要操作的变量填满整个 cache line，防止因为cache line 里混入和其他线程要修改的变量造成伪共享。<pre class=language-c++ data-lang=c++ style=color:#fdf4c1aa;background-color:#282828><code class=language-c++ data-lang=c++><span style=color:#fa5c4b>typedef struct </span><span>{
</span><span>    </span><span style=color:#fabd2f>int8_t</span><span> _before[</span><span style=color:#d3869b>60</span><span>];
</span><span>    </span><span style=color:#fabd2f>int32_t</span><span> value;
</span><span>    </span><span style=color:#fabd2f>int8_t</span><span> _after[</span><span style=color:#d3869b>60</span><span>];
</span><span>} </span><span style=color:#8ec07c>value</span><span>;
</span><span>
</span><span style=color:#fa5c4b>void </span><span style=color:#8ec07c>f</span><span>(value </span><span style=color:#fe8019>*</span><span style=color:#fdf4c1>data</span><span>) {
</span><span>    </span><span style=color:#fa5c4b>for </span><span>(</span><span style=color:#fa5c4b>int</span><span> i </span><span style=color:#fe8019>= </span><span style=color:#d3869b>0</span><span>; i </span><span style=color:#fe8019>&lt; </span><span style=color:#d3869b>10000000</span><span>; i</span><span style=color:#fe8019>++</span><span>) {
</span><span>        data-></span><span style=color:#fdf4c1>value </span><span style=color:#fe8019>+= </span><span style=color:#d3869b>100</span><span>;
</span><span>    }
</span><span>}
</span><span>
</span><span style=color:#fa5c4b>int </span><span style=color:#8ec07c>main</span><span>(</span><span style=color:#fa5c4b>void</span><span>) {
</span><span>    </span><span style=color:#fa5c4b>for </span><span>(</span><span style=color:#fa5c4b>int</span><span> i </span><span style=color:#fe8019>= </span><span style=color:#d3869b>0</span><span>; i </span><span style=color:#fe8019>&lt; </span><span style=color:#d3869b>100</span><span>; i</span><span style=color:#fe8019>++</span><span>) {
</span><span>        </span><span style=color:#fdf4c1>time_it(</span><span style=color:#b8bb26>"iteration"</span><span style=color:#fdf4c1>, []() {
</span><span style=color:#fdf4c1>            value a </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>{</span><span style=color:#d3869b>0</span><span style=color:#fdf4c1>}, b </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>{</span><span style=color:#d3869b>0</span><span style=color:#fdf4c1>}, c </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>{</span><span style=color:#d3869b>0</span><span style=color:#fdf4c1>}, d </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>{</span><span style=color:#d3869b>0</span><span style=color:#fdf4c1>};
</span><span style=color:#fdf4c1>            thread </span><span style=color:#fe8019>*</span><span style=color:#fdf4c1>threads[</span><span style=color:#d3869b>4</span><span style=color:#fdf4c1>] </span><span style=color:#fe8019>= </span><span style=color:#fdf4c1>{
</span><span style=color:#fdf4c1>                </span><span style=color:#fa5c4b>new </span><span style=color:#fdf4c1>thread(f, </span><span style=color:#fe8019>&</span><span style=color:#fdf4c1>a),
</span><span style=color:#fdf4c1>                </span><span style=color:#fa5c4b>new </span><span style=color:#fdf4c1>thread(f, </span><span style=color:#fe8019>&</span><span style=color:#fdf4c1>b),
</span><span style=color:#fdf4c1>                </span><span style=color:#fa5c4b>new </span><span style=color:#fdf4c1>thread(f, </span><span style=color:#fe8019>&</span><span style=color:#fdf4c1>c),
</span><span style=color:#fdf4c1>                </span><span style=color:#fa5c4b>new </span><span style=color:#fdf4c1>thread(f, </span><span style=color:#fe8019>&</span><span style=color:#fdf4c1>d),
</span><span style=color:#fdf4c1>            };
</span><span style=color:#fdf4c1>
</span><span style=color:#fdf4c1>            </span><span style=color:#fa5c4b>for </span><span style=color:#fdf4c1>(</span><span style=color:#fa5c4b>auto</span><span style=color:#fdf4c1> t </span><span style=color:#fe8019>:</span><span style=color:#fdf4c1> threads) {
</span><span style=color:#fdf4c1>                t->join();
</span><span style=color:#fdf4c1>            }
</span><span style=color:#fdf4c1>        })</span><span>;
</span><span>    }
</span><span>    </span><span style=color:#fa5c4b>return </span><span style=color:#d3869b>0</span><span>;
</span><span>}
</span></code></pre><p>将原本的 int 改成前后各有 60 字节填充的结构（前60字节防止 value 混入别人的 cache line，后60字节防止value后的变量混入cache line，124字节，对齐后128字节）。这个解决方法是典型的 <strong>用空间换时间</strong> 。再次运行基准测试，可以看到运行时间缩短了数倍。<pre style=color:#fdf4c1aa;background-color:#282828><code><span>iteration: 15ms
</span><span>iteration: 21ms
</span><span>iteration: 20ms
</span><span>iteration: 18ms
</span><span>iteration: 20ms
</span><span>iteration: 22ms
</span><span>iteration: 20ms
</span><span>iteration: 19ms
</span><span>iteration: 20ms
</span><span>iteration: 20ms
</span><span>... 略
</span></code></pre><h3 id=cache-line-yuan-li>cache line 原理</h3><p>Intel 在 2016 年发表的一篇文章，<a href=https://www.intel.com/content/www/us/en/developer/articles/technical/how-memory-is-accessed.html>How Memory Is Accessed</a>这样写道。<blockquote><p>Programming modern computers rarely requires an understanding of underlying hardware and software; consequently, most programmers do not know how the memory subsystem works.<p>However, such lack of knowledge can ultimately produce a 10x or worse slowdown in application performance – especially since the arrival of <a href=http://software.intel.com/en-us/articles/what-s-new-about-modern-hardware>new hardware technologies</a>.<p>...<p>The accesses propagating through the memory subsystem are a combination of a specific request and the needed physical addresses and, perhaps, data.<p>Data moves around most of the memory subsystem in 64-byte quantities called <em>cache lines</em>. A <em>cache entry</em>, which is some transistors that can store a physical address and a cache line, is filled when a cache line is copied into it. Pages are evenly divided into cache lines – the first 64 bytes of a 4096-byte page is a cache line, with the 64 bytes stored together in a cache entry; the next 64 bytes is the next cache line, etc.<p>Each cache line may:<ul><li>Not be cached<li>Occupy an entry in one cache<li>Be duplicated in several caches</ul><p>Cores, I/O devices, and other devices send requests to caches to either read or write a cache entry for a physical address. The lowest six bits of the physical address are not sent – they are used by the core to select the bytes within the cache line. The core sends separate requests for each cache line it needs.<ul><li><strong>Reads</strong> – If a cache has the requested physical address in a cache entry, the cache returns the data. If not, the cache requests the data from deeper in the memory subsystem and evicts some cache entry to make room. If the evicted cache entry has been modified, it must be written to the deeper memory subsystem as part of this eviction. This means a stream of reads may slow down because an earlier set of writes must be pushed deeper into the memory subsystem. A small queue of written data buffers the communication from the sender to the receiver.<li><strong>Writes</strong> – If the cache does not have the cache line in a cache entry, the cache reads it from deeper in the memory subsystem. It evicts some other physical address from its cache entry to make room for this cache line. The read is necessary to get all the 64 bytes, because the write is probably changing only some of them. The first time a cache entry is written, the cache entries of this physical address in all other caches are invalidated. This action makes the first write on a cache entry more expensive than later writes.</ul></blockquote><p>CPU访问主存时并不是直接从主存取数，而是先读入高速缓存，也就是在CPU的规格说明中提到的 L1/L2/L3 缓存。而且，CPU也不会傻乎乎地只从主存取一个字节、4个字节或8个字节，而是取更多数据放入缓存。<p>为什么？因为 <em>局部性原理</em> 。CPU设计者假设程序访问一个地址，则很快也会访问这个地址附近的其他地址。<p>这儿有个表格 <em>Numbers everyone should know</em>：<pre style=color:#fdf4c1aa;background-color:#282828><code><span>           0.5 ns - CPU L1 dCACHE reference
</span><span>           1   ns - speed-of-light (a photon) travel a 1 ft (30.5cm) distance
</span><span>           5   ns - CPU L1 iCACHE Branch mispredict
</span><span>           7   ns - CPU L2  CACHE reference
</span><span>          71   ns - CPU cross-QPI/NUMA best  case on XEON E5-46*
</span><span>         100   ns - MUTEX lock/unlock
</span><span>         100   ns - own DDR MEMORY reference
</span><span>         135   ns - CPU cross-QPI/NUMA best  case on XEON E7-*
</span><span>         202   ns - CPU cross-QPI/NUMA worst case on XEON E7-*
</span><span>         325   ns - CPU cross-QPI/NUMA worst case on XEON E5-46*
</span><span>      10,000   ns - Compress 1K bytes with Zippy PROCESS
</span><span>      20,000   ns - Send 2K bytes over 1 Gbps NETWORK
</span><span>     250,000   ns - Read 1 MB sequentially from MEMORY
</span><span>     500,000   ns - Round trip within a same DataCenter
</span><span>  10,000,000   ns - DISK seek
</span><span>  10,000,000   ns - Read 1 MB sequentially from NETWORK
</span><span>  30,000,000   ns - Read 1 MB sequentially from DISK
</span><span> 150,000,000   ns - Send a NETWORK packet CA -> Netherlands
</span><span>|   |   |   |
</span><span>|   |   | ns|
</span><span>|   | us|
</span><span>| ms|
</span></code></pre><p>具体数字依赖于具体的硬件平台，这个表格可以对访问速度建立大概的映像。当 L1/L2 缓存未命中，CPU不得不继续向更远、延时更长的设备寻求数据，每个 LLC Miss 都意味着 CPU 不得不花上成百上千倍的时间等待填充 cache line。而 LLC Miss 出现的频率越高，则意味着 CPU 执行的效率越低——绝大部分时间都在等待主存的数据。<p>更糟糕的是，有时候 CPU 真的就是傻等(stall)，不专门分析甚至都不知道程序根本没跑出应有的速度。<blockquote><p>Modern cores use both <a href=https://en.wikipedia.org/wiki/Out-of-order_execution>out-of-order execution</a> and <a href=https://en.wikipedia.org/wiki/Hyper-threading>hyperthreading</a> to find and to do something useful while other instructions wait for data to be fetched.<p>If nothing useful can be done, the core stalls. Unfortunately, the OS is almost unaware of the stall: the application appears to be running, and it is hard to tell if the application is slower than it should be. You need tools to examine <a href=https://en.wikipedia.org/wiki/Hardware_performance_counter>hardware performance counters</a> to see stall details.</blockquote><p>回顾基准测试代码，仅仅是连续分配内存就可以获得百倍的性能改善，超值。<p>引用前文来给 cache line 小节结尾：<blockquote><p>However, such lack of knowledge can ultimately produce a 10x or worse slowdown in application performance – especially since the arrival of <a href=http://software.intel.com/en-us/articles/what-s-new-about-modern-hardware>new hardware technologies</a>.</blockquote><h2 id=zong-jie>总结</h2><p>什么是 cache line？<blockquote><p>Data moves around most of the memory subsystem in 64-byte quantities called <em>cache lines</em>.</blockquote><p>cache line 如何影响性能？</article><p class=tags-data><a href=/tags/c>/c++/</a></p><script data-repo-id="MDEwOlJlcG9zaXRvcnkzOTg0ODYyMTg=" async crossorigin data-category=Announcements data-category-id=DIC_kwDOF8Bqys4Cegmn data-emit-metadata=0 data-input-position=bottom data-lang=zh-CN data-mapping=pathname data-reactions-enabled=1 data-repo=nnnewb/nnnewb.github.io data-strict=0 data-theme=noborder_light id=giscus_script src=https://giscus.app/client.js></script></main><footer><hr><div id=footer-container><div><p style=text-align:center>Copyright © 2018-2024 weakptr <a href=mailto:weak_ptr@outlook.com>&lt;weak_ptr@outlook.com></a><p style=text-align:center>Built with <a rel="noopener noreferrer" href=https://www.getzola.org target=_blank>Zola</a> using <a rel="noopener noreferrer" href=https://github.com/Speyll/anemone target=_blank>anemone</a> theme, <a rel="noopener noreferrer" href=https://speyll.github.io/suCSS/ target=_blank>suCSS</a> framework & <a rel="noopener noreferrer" href=https://github.com/Speyll/veqev target=_blank>veqev</a>, modified by <a rel="noopener noreferrer" href=https://github.com/nnnewb/ target=_blank>nnnewb</a>.<p style=text-align:center>Theme and color theme licensed under <a rel="noopener noreferrer" href=https://en.wikipedia.org/wiki/Licence_MIT target=_blank>MIT</a>.</div></div></footer>